---
title: "エージェント実行の高度な制御 (1) 計画駆動パターン"
emoji: "📋"
type: "tech"
topics: ["ai", "go", "llm", "agent"]
published: false
---

この記事はアドベントカレンダー「Goで作るセキュリティ分析LLMエージェント」の18日目です。

今回のコードは https://github.com/m-mizutani/leveret の [day18-plan-execute](https://github.com/m-mizutani/leveret/tree/day18-plan-execute) ブランチに格納されていますので適宜参照してください。

# 生成AIエージェントの実行における迷走

- LLMの短く明確なタスクだと、以前に実装したFunction Callingのループで問題なく完了してくれる
- しかし、やや複雑な処理だったり、複数の要件が発生するようなタスクだと急に迷走をはじめる
  - 横道にそれはじめて目的を見失う
  - なんか頑張っているがよくわからないことを延々と続ける
- なぜこんなことが起きるのか？
  - プロンプトに目的が含まれていても部分的に忘れる Lost in the middle現象など
    - 入力データが大きくなりすぎると真ん中あたりの情報の優先度が低くなる現象
  - コンテキストが長くなりすぎた結果、ヒストリが compression される過程で目的が見失われてしまう
    - 要約で適切に目的を残すように指示しても、文脈が失われたりしてしまう
      - 大量データを要約しようとすると難しい
    - trimとかだともっと深刻な問題に
  - 直近のヒストリに影響されるので、一度おかしな推論をしたり仮説を立てたりすると、そのまま突き進んでいく
    - そのまま返ってこなくなることもしばしば
- LLMエージェントの

# 生成AIエージェントの行動思考手法

- こうした迷走を防ぐために生成AIエージェントを実行する際にエージェントの行動を制御する手法がいくつか存在する
- LLM Agent Architectures, Reasoning strategiesなどと呼ばれる
- 本アドベントカレンダーでは「行動思考手法」と呼ぶ
  - 行動思考手法は多岐にわたる
- 具体的には、単純にツール実行を繰り返すのではなく、ツール実行の合間にさらに生成AIによるコンテンツ生成を挟み込み、その結果によって次の行動の選択を方法の総評
  - ここまでの要約を与えたり、フルHistoryを与えたりなど手法は様々だが、とにかくタスクの実行とは別に実行方針制御も生成AIでやる、というのがポイント
  - （ここに単純ループと行動思考手法の違いのフローチャートを書く）
- 筆者の認識だとメジャーなものは以下辺り
  - **ReAct (Reason + Act)**:
    - 汎用的に使える思考＋実行を繰り返す手法
    - function callingと比較すると、ReActは思考過程をテキストとしてhistoryに含められる一方、function callingは構造化されたJSON形式で確実にツールを呼び出せる
      - ReActの利点は推論ステップを明示的にプロンプトに示して制御することだが、本質的にはhistory管理の一種である
  - **Plan & Execute**:
    - 計画フェーズと実行フェーズを分離することで計画に沿ったタスクをこなす
    - 安定的に動作する反面、探索的なタスクには弱い
    - 初期計画が静的なため、予期しない状況への適応が困難であり、タスクが順次実行されるため並列化による高速化も制限される
  - **Reflexion**
    - 自己評価・改善ループ型
    - 実行するたびに結果が目的を達成したか？というのを確認し、だめなら内省する
    - それをもとに再実行を繰り返す
    - 探索的な処理に適している
- 研究分野も含めるとより多様な手法がある
  - 今回の記事では各手法の詳細には踏み込まない
  - また最新の研究成果は追随できていない（し、それをここで書いてもあっという間に陳腐化する）
  - 興味がある人は自分で最新の情報を調べてくれ
- 2025年現在の最新のエージェントでは、これらの手法を組み合わせたり、必要に応じて切り替えたりしながら利用している
  - 例えばタスクによって手法を変えるとか
  - ある手法のなかでのツール実行を別の行動思考手法で制御するとか
  - 万能な行動思考手法はなく、最適手法に関しての研究が進んでいる

# Plan & Executeパターンの利用

## セキュリティアラートの分析と Plan & Execute パターン

- 今回のLLMエージェントでは事前に計画を立てて遂行していく Plan & Execute パターンを採用する
  - これは対象とする「セキュリティアラートの分析」というユースケースに依存する
- 「セキュリティアラートの分析」のユースケース
  - (1) まずセキュリティアラートが飛んでくる
    - この時点でなにか問題が発生している可能性が示唆されている
      - これにはどのような問題かも（ちょっと考えると）わかるようになっている
    - そして基本的に問題に関する手がかりが記されている
  - (2) 次にするべきはその手がかりからそのアラートが実際に影響を及ぼしたのか
    - これは関連するログやシステムの状態などを調べる
    - 同時にそのリソースに関する社内のアクティビティなどを調べる
    - という観点で考えると、実はあまり探索的なことをしていないのである
      - ここでいう「探索的」というのは「新しい情報を取得してそれを元に次の行動を変更・決定する、というのを連続してやるもの」という意味
    - つまりアラートを見た時点で、アクセス可能なデータソースから調査すべき情報というのは概ね定まる
      - もちろんなにか見つけた際に深堀りが必要になったり、期待していたデータが発見されなかったので修正するという事は考えられる
      - しかしまず初手はこれとこれとこれ、みたいに、熟練のアナリストはおおむねあたりをつけられる（と筆者は考えている）
    - という性質から、まず計画を立てることが重要である
      - むしろ一つの事象に囚われてあっちこっちで余計な関心を掘り始めるほうがよくない
  - (3) もし影響があると判断された場合は影響の範囲を調べる、というのがエージェントのタスクとなる
    - その場合もそのAlertに関連するリソースや主体がどのような行動をしていたか？というのがまず調べることになる
    - そうすると最初に探すべきキーとDBは容易に推定できるため、これも事前計画と相性がよい
      - もちろんこのタスクについては、そっからさらに深堀りする可能性がある
      - ただそれはタスク全体じゃなくて、個別のタスクの中で深堀りしていくっていういのがポイント
      - この場合はPlan & ExecとReflexionを組み合わせるという技もやりうる
      - ただややこしくなるので、今回はplan & execだけね
- ちなみに全く無の状態から始めるタイプの脅威ハンティングだと全く違った戦略になる
  - その場合はそもそも大量のデータからどうやって分析するかの取っ掛かりをいかに作るかが問題
  - こういうケースだと生成AIを使わない方がいいかもしれない
  - このようにLLMエージェントを使った問題解決では（依然として）データをどう扱うのが最適なのか人間がしっかり考える必要がある
  - 脅威ハンティングについて筆者はそこまで専門ではないので割愛

## 基本的な考え方

- まず計画をたてる
  - ユーザーからの入力をもとに計画を立てる
  - この際なるべく別途システムプロンプトでコンテキストを与えてあげるとよい
    - AIのロール（セキュリティ分析のサポートをする役目など）

- 並列実行は今回扱わない

## 具体的な処理フロー



# まとめ
