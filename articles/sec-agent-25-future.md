---
title: "Goで作るセキュリティ分析LLMエージェント(25): より高度な分析と深刻度判定"
emoji: "🌟"
type: "tech"
topics: ["ai", "llm", "agent"]
published: true
---

この記事はアドベントカレンダー「[Goで作るセキュリティ分析LLMエージェント](https://adventar.org/calendars/11354)」の25日目、最終日です。

最終日となる本日は実装ではなく、今後の構想について話をします。これまで24日間にわたってセキュリティアラート分析のためのLLMエージェントを構築してきましたが、実はまだ実現できていない重要な機能があります。それが「深刻度判定の自動化」です。

これは筆者がこれから取り組もうとしていることであり、もしかすると他のベンダが先に実装するかもしれません。トピックとしては、今回のアドベントカレンダーで実装したLLMエージェントをより高度化するとしたらどうするか、という内容になります。来年くらいには筆者、あるいは誰かが実現できているのではないかと考えています。もしチャレンジしてみた方がいたら是非教えてください。

# なぜLLMエージェントは分析止まりなのか

これまで実装してきたLLMエージェントは、あくまで分析、あるいは分析の補助をするものでした。最終的な判断は人間がやること（human-in-the-loop）というスタンスでこれまで解説してきましたが、本当にそれで満足でしょうか。もっと期待してもいいのではないでしょうか。

## 本当にやってほしいこと

本当にやってほしいことの一つは、深刻度の判定をやりきってほしいということです。ここでいう深刻度（severity）とは、実際に組織にとって被害がでる確度の高さ（影響度）、およびどのくらい急いで対応する必要があるか（緊急度）を統合したものと定義します。

これができるようになると初期トリアージが一気に進みます。本当にトリアージと対応が必要なアラートだけに人間が介入すればよくなるため、ある程度の防御ができている環境であればアラートの9割近くは影響のないものとなり、実際に影響がある（侵害が発生している、あるいは直近で発生する可能性が高い）ものだけに人間の対応を限定できます。言い換えれば、これはオンコールの一次請けができるようになるということです。これによって人間がオンコールで24時間365日張り付く必要がなくなります。中小規模の組織（500人程度まで）では24時間365日体制を作るのは極めて困難であり、この機能が実現できると大きな助けになります。

## 現状の課題

もちろん現状でもLLMに「このアラートは対応するべきかどうか」と尋ねればやってくれます。しかしやったことがある人ならわかると思いますが、全く信用できません。期待した答えにならないのです。

これは一般的な回答になってしまっているためです。例えるならCVSSのようなものです。CVSSは脆弱性のリスクを定量化してくれますが一般化された内容であり、どの組織にもあてはまるものではありません。例えばCVSSスコア8の脆弱性よりも、スコア5の脆弱性の方が組織によっては深刻である、ということも当然ありえます。これと同様に、LLMにそのままアラートのリスク評価を聞くと、組織内における文脈を無視して「一般的な」影響のあるなしを判断してしまいます。そのため逆にLLMの回答に惑わされないよう、熟練者なら質問しないほうが良いという状況すらあります。

なお、インシデントレスポンスや問題の修正もやってほしいところですが、これはさらに難しく、またドメインも異なり筆者も詳しいとは言い切れないため今回は割愛します。

## なぜ適切な深刻度判断ができないのか

ここからは仮説になります。実際、LLMのモデル自体の性能はどんどん上がっています[^swebench][^openai][^gemini][^opus]。そのため論理的な回答を導くというプロセスだけで考えれば、すでに十分な推論力を持っていると考えられます。

では何が足りないのかというと、ここまでも散々言ってきた通りコンテキストが足りないのです。分析に伴ってアラートそのものだけでなく様々なコンテキストを与える必要があります。これを適切に与えられるようになったとき、深刻度判定の精度の向上が見込めるのではないかと考えています。

[^swebench]: https://www.swebench.com/
[^openai]: https://openai.com/index/introducing-gpt-5-2
[^gemini]: https://deepmind.google/models/gemini/pro/
[^opus]: https://www.anthropic.com/news/claude-opus-4-5

# 足りてない情報は何か

では、適切な深刻度判定を行うためには具体的にどのような情報が必要なのでしょうか。自分でアラートを分析し深刻度を判断するとき、何を参考にしているかを思い返すとわかりやすいでしょう。

LLMは情報を揃えればある程度妥当な判定をしてくれるようになってきました。つまり、自分が深刻度判断するときに使っている知識や集めている情報がそのまま必要になる、ということです。実際に整理してみると、必要な知識がとても広範にわたることがわかります。以下に主要なカテゴリを挙げますが、これでも網羅されていない可能性があります。

## 組織のコンテキスト

### システムが扱うデータの機密性・重要度

個人情報、機密情報、公開情報などデータの性質によってリスクは大きく変わります。例えば公開情報しか扱わないシステムであれば情報漏洩のリスクは低くなります。検証環境などで本番データが入っていない場合も、深刻度は比較的低めに見積もることができます。もちろん検証環境も攻略の足がかりになる可能性はあるので対応しなくて良いわけではありませんが、緊急度には影響します。逆に個人の医療情報を扱うシステムであれば、漏洩時の影響は甚大です。

### システムのビジネスインパクト

システムが停止した場合のビジネスへの深刻度も重要な判断材料です。例えばECサイトであれば停止すると直接売上に影響します。社内の勤怠管理システムであれば外部への影響はありませんが業務は滞ります。これらによって緊急度が左右されます。

### 組織のリスク許容度

組織としてどの程度のリスクまで許容するのかという方針も重要です。扱っているサービスや業種によって法令・ガイドライン対応やレピュテーションリスクへの感度が変わります。これらによって同じアラートでも対応の優先度が変わってきます。

## 実装のコンテキスト

### プロダクト・システムの実装

プロダクトの実装内容やシステムの認証設定も深刻度判定に影響します。不正ログインの試みを検知した場合でも、そのユーザやシステムにMFA（多要素認証）が設定されていれば影響はないと推定できます。ただし、これはどちらにしてもログを確認すべきではあります。逆にパスワードのみで認証していた場合、侵害を受けた可能性を判断する必要があります。

検知されたアラートに関連する機能の実装詳細も重要です。該当エンドポイントは何を処理しているのか、入力検証は実装されているか、使用しているライブラリやフレームワークのバージョンは何か、といった情報が必要になります。例えばSQLインジェクションの疑いがあるアラートでも、ORMを使っていてパラメータ化クエリが徹底されていれば影響は低くなります。一方で文字列連結でクエリを組み立てているような実装であれば、高リスクです。このように実装そのものを追跡できるような能力が必要です。

既知の脆弱性や技術的負債の有無も確認する必要があります。脆弱なライブラリのバージョンを使っていないか、過去のペネトレーションテストで指摘された未修正の問題はないか、といった情報です。これらがある場合、攻撃者が悪用できる既知の手法が存在する可能性が高くなります。

### インフラや基盤の設計や実装

インフラや基盤の認証・認可設定も確認が必要です。利用しているユーザ、サービスアカウントやロール、そしてその権限範囲などを把握する必要があります。強い権限を持つ主体が侵害された場合、影響は大きくなります。また重要なデータを扱う主体も同様です。逆に権限がちゃんと切られていてかつ重要なデータを扱っていなければ緊急度は低くなります。

インフラとしてのデータ配置や公開などの方針も重要です。インフラの設定としてデータ露出に関する方針がどうなっているのかを把握する必要があります。例えばオブジェクトストレージの公開範囲が任意のユーザになっていても、Webサイトの公開リソースであれば全く問題ありません。逆に意図せずそのような設定になっていて情報漏洩を起こしている可能性もあります。これは担当者に問い合わせるという方法もありますが、組織内になんらかのルールがあれば、それに則っているかどうかで影響を判定できます。

ネットワークセグメンテーションや境界防御の設定も見る必要があります。ネットワークが適切に分離しているか、疎通は必要最低限に設定されているか、といった情報です。これによって攻撃を受けたシステムから他のシステムへの横展開がどの程度可能かが変わります。例えば完全に隔離された環境であれば、そのシステムだけの問題で済む可能性が高くなります。一方でフラットなネットワーク構成であれば、一箇所の侵害が全体に波及するリスクがあります。

## 業務のコンテキスト

当該ユーザやシステムがどのような業務をしているかの理解も必要です。どのようなシステムと繋がって何をするためのシステムなのか、どのような業務をしている人でどのようなデータを扱う人なのか、といった情報を把握することで、適切な行動が推定され、アラートとして検知された内容が意図的なのかどうかの判断ができます。

当該システムに対する最近の変更履歴も重要な情報源です。直近のデプロイや設定変更はあったかを確認します。新しい機能をリリースした直後であれば、その機能に起因するアラートである可能性が高くなります。ただし設定変更によって意図せず脆弱な状態になっている可能性もあり、そこも含めて深刻度を判定する必要があります。変更履歴を把握していれば、少なくともアラートの原因を特定しやすくなります。

現在進行中のプロジェクトや業務イベントも考慮すべき情報です。新機能リリース直後ではないか、大規模キャンペーン実施中ではないか、といったタイミング情報です。これらのイベント時には通常と異なるトラフィックパターンが発生するため、このようなタイミング情報を加味することで、アラートの優先度を適切に判断できます。

## 脅威のコンテキスト

攻撃者の活動状況も判断材料になります。ドメインによっては同業他社への類似攻撃の発生状況が参考になります。例えば金融業界で特定のマルウェアキャンペーンが活発化しているという情報があれば、同様のアラートの優先度は上がります。

また最近活発な攻撃手法や領域に関する情報も、アラートの深刻度判定に影響します。脅威インテリジェンスフィードやセキュリティベンダのレポートから得られる情報を、組織の状況と照らし合わせることで、より精度の高い判定が可能になります。

# 解決のためのアイディア

先述した通り、使うべき情報は多岐にわたり一筋縄ではいきません。とはいえ、いくつかのアプローチを組み合わせることで、この問題に対処できる可能性があります。以下では筆者が考えている解決策のアイディアをいくつか紹介します。

## 組織内情報の検索性向上

まず基本となるのは、組織に関連した情報をまとめ、エージェントが真の意味で検索可能な状態にすることです。

### ドキュメントの整備と構造化

ドキュメント、設計書、運用手順書、さらには事業関連の状況、セキュリティポリシー、組織図、業務分掌などの情報を検索可能な形で整備する必要があります。そもそもまずそれらの整備が必要であり、そのうえでシステムの機密性、ビジネスインパクト、リスク許容度なども含めて分かるように情報をまとめて検索可能にします。多くの組織では、こうした情報が散在していたり、属人化していたりするため、まずは情報の集約と構造化が第一歩になります。

### 「知らないものは探さない」問題への対処

ただし、おそらくただのRAGではうまくいきません。探すべき情報の範囲が横断的であり、エージェントが直接的に欲しい情報へたどり着くのは困難です。真の意味での「検索可能」は本当にエージェントがその情報にたどり着けてこそです。たどり着けないなら理論上は検索可能でも意味はありません。

そもそも何を探せるのか、ということからエージェントが知る必要があります。これは「知らないものは探さない」問題と呼べるでしょう。人間のアナリストであれば、経験から「こういう情報があるはず」という見当をつけて探索できますが、エージェントにはその経験がありません。

より効率的に知識・情報を検索するためには、より先進的なRAGのような仕組みが必要になります。例えばGraphRAGのような技術が候補になります。GraphRAGは知識をグラフ構造で表現することで、関連情報を辿りやすくする技術です。これはセキュリティ分析という文脈・ドメイン特有の問題もあると考えられ、実地でいろいろと試していくしかありません。

### 情報の咀嚼と要約

また、検索されたドキュメントやポリシーなどをそのままエージェントに渡すと、単にコンテキスト消費が多くなるだけになってしまいます。重要なのは検索から得られた情報を、うまく咀嚼して今の状況にあわせて解釈し、適切な形でメインエージェントへ返すことです。ここでもサブエージェントが活躍します。検索を担当するエージェントが、単に文書を返すのではなく、「このアラートの文脈において重要な情報はこれ」という形で要約して返すイメージです。

## 開発・インフラ関連データへのアクセス機能の提供

次に重要なのは、開発・インフラ関連のデータへのアクセス機能を提供することです。静的なドキュメントだけでなく、実際のシステムの状態を動的に取得できることが、正確な深刻度判定には不可欠です。そのためにいろいろな権限を付けたりツールを用意して、エージェントがアクセスできる状態を作ります。

### ソースコードリポジトリへの読み取りアクセス

アラート関連のエンドポイントやロジックの実装を直接確認できるようにします。入力検証、認証実装、使用ライブラリのバージョンなどを自動抽出する仕組みが必要です。

ただし、これについては単純にアクセスできれば良いというわけではなく、コードを追跡するようなエージェントとしての振る舞いが必要です。例えば「このエンドポイントはどのように入力を検証しているか」を調べるには、ルーティング定義からハンドラを特定し、そこから呼び出されている検証関数を追跡するといった複数ステップの分析が必要になります。これはCursorやClaude Codeのようなコーディングエージェントの方が得意な領域です。またコストも掛かるので、クリティカルそうなアラートだけに絞るといった工夫も必要になりそうです。

### IaCおよび実際のインフラ情報の読み取り

権限設定、ネットワーク構成、公開範囲などをTerraformやCloudFormationといったIaC（Infrastructure as Code）から読み取ります。さらに実際のインフラにアクセスして情報を読み取る機能も必要です。例えばCloud Asset Inventoryの情報をBigQueryに外出しして検索するような方法もできなくはありませんが、やはり生の情報が必要になる場面も多いでしょう。

### CI/CDパイプラインやデプロイ履歴へのアクセス

最近のデプロイタイミングとアラート発生時刻を突き合わせることで、デプロイ内容から新機能起因かどうかを判断できます。また、どのソースコードがどこにどういう形でデプロイされたかを追跡できることも重要です。意外とソースコードのリポジトリと実稼働プロダクトが綺麗に繋がらない場合もあります。これを人間がちまちま調べるのではなく、エージェントにやらせたいところです。

### 依存関係管理ツールとの連携

DependabotやRenovateといった依存関係管理ツールと連携して、既知の脆弱性や未適用パッチの情報を取得します。CVEやセキュリティアドバイザリとの関連を自動判定することで、アラートの深刻度判定に活用できます。

## 関係者との対話の代行

すべての情報がシステムから取得できるわけではありません。特に「このシステムの意図された挙動は何か」といった設計意図や、「この設定は一時的なものか恒久的なものか」といった運用上の判断は、担当者に聞かなければわからないこともあります。そこで、関係者に「聞く・問い合わせる」ということ自体をエージェントに代行させるアプローチも考えられます。

システムオーナーやSREへの自動問い合わせを実装します。不明な設定や意図が不明なアラートについて、チャットシステム（SlackやTeams）で質問を代行させます。そこまで高度な会話を求めなくても、「Yes」「No」で答えられるようにして、ボタンで回答させる形式で良いはずです。人間の回答を待ってから深刻度判定を継続します。あるいは「このアラートについて詳しい人は誰ですか」と聞いて、適切な担当者を指名してもらうといった仕組みも考えられます。

このアプローチの利点は、人間の知識を活用しつつ、エージェントが24時間365日稼働できることです。夜間や休日に発生したアラートでも、翌営業日に担当者が出社したタイミングで質問への回答を得て、判定を完了できます。

## マルチエージェント化

ここまでいくつか方法を挙げてきましたが、これらのアプローチは1つ1つの処理がとても複雑です。そうするとコンテキスト限界だけでなく、余計な処理によるコンテキスト汚染もかなり気にする必要がでてきます。こういった側面を考えると、やはりマルチエージェント化が必要になります。

### タスクの専門家を作る

マルチエージェントは専門性をエージェントごとに分離すると思われがちですが、個人的にはそれはちょっと違っていて、本質は「タスクの専門家」を作ることだと考えています。例えばここまでの例で言うと「資料検索の専門家」「ポリシー解釈の専門家」「ソースコード分析の専門家」といった具合です。これは人間の単位でみる専門性とは違います。

各エージェントが特化したツールセットを持つことで効率化できます。例えばコード分析エージェントはGitHub API、インフラエージェントはクラウドAPIといった具合です。利用できるツールが多すぎると混乱するという問題もあるので、ツールの分散はその防止策でもあります。

### 並列性は本質ではない

マルチエージェントについては並列性も利点として挙げられますが、これも個人的にはあまり本質ではないと考えています。直列でも正しく問題を解決できればものすごく価値があります。依存関係を本当に正しく事前に計画できるのかには疑義があります。「早すぎる最適化は悪手」という格言もあります。

ということで現状世間で言われているマルチエージェントとは本質がややずれるものの、エージェントを分散させるのが今後の発展の1つの鍵であると予想されます。

### エージェント間の意見の対立

またマルチエージェントでは、主たるエージェントがサブエージェントを使いこなすものとイメージされがちですが、並列する2つのエージェントを用意して意見を戦わせるという手法も考えられます。異なる前提や異なるモデル、プロンプトを与えることによって違う視点を持たせられます。人間の役割分担と同じく、例えばセキュリティ担当としての深刻度と事業担当者としての深刻度というのは異なってきます。そのため異なる役割を与えた時の結論は違うはずで、それを綱引きさせるというのは重要な判断においてはありえると考えています。もちろんコストや時間はかかります。

3つのエージェントでそれを判断するような仕組みが作れると、某スーパーコンピューターみたいになりそうです。実際に複数エージェントを戦わせる手法（ensembleやdebateなど）は研究が進められていますが、まだ実用段階ではないとのことです。逆に精度が下がる可能性もあるらしいです。とはいえ夢がありますよね。

![](https://storage.googleapis.com/zenn-user-upload/ce0f7ed2a0ce-20251223.png)

# まとめ

