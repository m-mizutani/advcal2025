---
title: "Goで作るセキュリティ分析LLMエージェント(25): より高度な分析と深刻度判定"
emoji: "🌟"
type: "tech"
topics: ["ai", "llm", "agent"]
published: true
---

この記事はアドベントカレンダー「[Goで作るセキュリティ分析LLMエージェント](https://adventar.org/calendars/11354)」の25日目、最終日です。

- 最終日は実装はなしで、構想の話をする
- これから筆者が取り組もうとしていることであり、どこかのベンダが先に実装するかもしれない
- トピックとしては今回実装したLLMエージェントをより高度化するとしたらどうするかという話
- 来年くらいには自分、あるいは誰かが実現できているかもという気はする
- チャレンジしてみた人がいたら是非教えて下さい

# なぜLLMエージェントは分析止まりなのか

- これまで実装してきたLLMエージェントはあくまで分析、あるいは分析の補助をする
  - 最終的な判断は人間がやること（human-in-the-loop）というスタンスでこれまで解説してきた
  - でも本当にそれで満足か？ もっと期待してもいいんじゃないか？
- 本当にやってほしいことは何か
  - 深刻度の判定をやりきってほしい
    - 深刻度（severity）＝実際に組織にとって被害がでる確度の高さ（影響度）、およびどのくらい急いで対応する必要があるか（緊急度）を統合したものとする
    - これができると初期トリアージが一気に進む
    - 本当にトリアージ＋対応が必要なやつだけ人間が介入すればよくなる
      - ある程度ちゃんとした防御ができていればアラートの9割近くは影響のないものになる
      - 実際に影響がある（侵害が発生している、あるいは直近で発生する可能性が高い）ものだけに人間の対応を限定したい
    - 言い換えるとオンコールの一次請けができるようになる
      - これによって人間がオンコールで24/365張り付く必要がなくなる
      - 中小規模の組織（〜500人程度）では24/365体制を作るのは極めて困難であり、これができると非常にありがたい
  - このアラートは対応するべきかどうか？の判定をする
    - もちろん現状でも判定してと言うとやってくれる
    - しかしやったことあると分かるのだが、全く信用ならない。期待した答えにならない
    - これは一般的な回答になっているためである。例えるならCVSSのようなもの
      - CVSSは脆弱性のリスクを定量化してくれるが一般化された内容でありどの組織にもあてはまるものではない
      - 例えばcvssのスコア8より、スコア5の方が組織によっては刺さるということも当然ありえる
      - これと同様にLLMにそのままアラートのリスク評価を聞くと、組織内における文脈を無視して「一般的な」影響のあるなしを判断してしまう
    - そのため逆にLLMの回答に惑わされないよう、熟練者なら質問しないほうが良いまである
  - もちろんインシデントレスポンスや問題の修正もやってほしいがこれはさらに難しく、またドメインも異なり筆者も詳しいとは言い切れないため今回は割愛する
- なぜ適切な深刻度判断ができないのか？
  - ここからは仮説
  - 実際、LLMのモデル自体の性能はどんどんあがっている[^swebench][^openai][^gemini][^opus]
  - そのため論理的な回答を導くというプロセスだけで考えれば、すでに十分な推論力を持っていると考えられる
  - では何が足りないのかというと、ここまでも散々言ってきた通りコンテキストが足りない
  - 分析に伴ってアラートそのものだけでなく様々なコンテキストを与える必要がある
  - これを適切に与えられるようになったとき、深刻度判定の精度の向上が見込めるのではないか

[^swebench]: https://www.swebench.com/
[^openai]: https://openai.com/index/introducing-gpt-5-2
[^gemini]: https://deepmind.google/models/gemini/pro/
[^opus]: https://www.anthropic.com/news/claude-opus-4-5

# 足りてない情報は何か

- 自分でアラートを分析し深刻度を判断をするとき何を参考にしているか？ というのを思い返すとわかりやすい
- LLMは情報を揃えればある程度妥当な判定をしてくれるようになってきたため、自分が深刻度判断するときに使っている知識や集めている情報がそのまま必要になる、ということである
- 実際に整理してみると知識がとても広範にわたるということがわかる
- 下記に例を挙げるが、これも網羅されていない可能性がある

## 組織のコンテキスト

- システムが扱うデータの機密性・重要度
  - 個人情報、機密情報、公開情報などデータの性質によってリスクは大きく変わる
  - 例えば公開情報しか扱わないシステムであれば情報漏洩のリスクは低い
  - 検証環境などで本番データが入っていないなども、深刻度は比較的低めに見積もることができる
    - もちろん検証環境も攻略の足がかりになる可能性はあるので対応しなくて良いわけではないが、緊急度には影響する
  - 逆に個人の医療情報を扱うシステムであれば、漏洩時の影響は甚大
- システムのビジネスインパクト
  - システムが停止した場合のビジネスへの深刻度
  - 例えばECサイトであれば停止すると直接売上に影響する
  - 社内の勤怠管理システムであれば外部への影響はないが業務は滞る
  - これらによって緊急度が左右される
- 組織のリスク許容度
  - 組織としてどの程度のリスクまで許容するのか
  - 扱っているサービスや業種によって法令・ガイドライン対応やレピュテーションリスクへの感度が変わる
  - これらによって同じアラートでも対応の優先度が変わる

## 実装のコンテキスト

### プロダクト・システムの実装

- プロダクトの実装内容やシステムの認証設定
  - 不正ログインの試みを検知した場合でも、そのユーザやシステムにMFAが設定されていれば影響はないと推定できる
    - ただこれはどちらにしてもログを確認すべきではある
  - 逆にパスワードのみで認証していた場合、侵害を受けた可能性を判断する必要がある
- 検知されたアラートに関連する機能の実装詳細
  - 該当エンドポイントは何を処理しているのか、入力検証は実装されているか
  - 使用しているライブラリやフレームワークのバージョンは何か
  - 例えばSQLインジェクションの疑いがあるアラートでも、ORMを使っていてパラメータ化クエリが徹底されていれば影響は低い
  - 一方で文字列連結でクエリを組み立てているような実装であれば、高リスク
  - 実装そのものを追跡できるような能力が必要である
- 既知の脆弱性や技術的負債の有無
  - 脆弱なライブラリのバージョンを使っていないか、過去のペネトレーションテストで指摘された未修正の問題はないか
  - これらがある場合、攻撃者が悪用できる既知の手法が存在する可能性が高い

### インフラや基盤の設計や実装

- インフラや基盤の認証・認可設定
  - 利用しているユーザ、サービスアカウントやロール、そしてその権限範囲など
  - 強い主体が侵害された場合影響が大。また重要なデータを扱う主体も
  - 逆に権限がちゃんと切られていてかつ重要なデータを扱っていなければ緊急度は低い
- インフラとしてのデータ配置や公開などの方針
  - インフラの設定としてデータ露出に関する方針がどうなっているのか
  - 例えばオブジェクトストレージの公開範囲が任意のユーザになっていても、Webサイトの公開リソースであれば全く問題ではない。逆に意図せずそのような設定になっていて情報漏洩を起こしている可能性もある
  - これは担当者に問い合わせるという方法もあるが、組織内になんらかのルールがあれば、それに則っているかどうかで影響を判定できる
- ネットワークセグメンテーションや境界防御の設定
  - ネットワークが適切に分離しているか、疎通は必要最低限に設定されているか
  - 攻撃を受けたシステムから他のシステムへの横展開がどの程度可能かが変わる
  - 例えば完全に隔離された環境であれば、そのシステムだけの問題で済む可能性が高い
  - 一方でフラットなネットワーク構成であれば、一箇所の侵害が全体に波及するリスクがある

## 業務のコンテキスト

- 当該ユーザやシステムがどのような業務をしているかの理解
  - どのようなシステムと繋がって何をするためのシステムなのか
  - どのような業務をしている人でどのようなデータを扱う人なのか
  - それによって適切な行動が推定され、アラートとして検知された内容が意図的なのかどうかの判断ができる
- 当該システムに対する最近の変更履歴
  - 直近のデプロイ、設定変更はあったか
  - 新しい機能をリリースした直後であれば、その機能に起因するアラートである可能性が高い
    - ただし設定変更によって意図せず脆弱な状態になっている可能性もある
    - そこも含めて深刻度を判定する
  - 変更履歴を把握していれば、少なくともアラートの原因を特定しやすい
- 現在進行中のプロジェクトや業務イベント
  - 新機能リリース直後ではないか、大規模キャンペーン実施中ではないか
  - これらのイベント時には通常と異なるトラフィックパターンが発生する
  - このようなタイミング情報を加味することで、アラートの優先度を適切に判断できる

## 脅威のコンテキスト

- 攻撃者の活動状況
  - ドメインによっては同業他社への類似攻撃の発生状況
  - また最近活発な攻撃手法や領域に関する情報

# 解決のためのアイディア

- 先述した通り、使うべき情報は多岐にわたり一筋縄ではいかない
- とはいえ

## 組織内情報の検索性向上

とにかく組織に関連した情報をまとめ、エージェントが真の意味で検索可能な状態にする

- ドキュメント、設計書、運用手順書、さらには事業関連の状況、セキュリティポリシー、組織図、業務分掌などについての情報などを検索可能な形で整備
  - そもそもまずそれらの整備が必要である
  - そのうえでシステムの機密性、ビジネスインパクト、リスク許容度なども含めて分かるように情報をまとめて検索可能にする
- ただしおそらくただのRAGではうまく行かない
  - 探すべき情報の範囲が横断的であり、エージェントが直接的に欲しい情報へたどり着くのは困難
  - 真の意味での「検索可能」は本当にエージェントがその情報にたどり着けてこそ。たどり着けないなら理論上は検索可能でも意味はない
    - そもそも何を探せるのか？ ということからエージェントが知る必要がある
    - 「知らないものは探さない」問題
  - より効率的に知識・情報を検索するためにはより先進的なRAGのような仕組みが必要
    - 例えばGraphRAGのような技術
    - これはセキュリティ分析という文脈・ドメイン特有の問題もあると思う
    - 実地でいろいろと試していくしかない
- また検索されたドキュメントやポリシーなどをそのままエージェントに渡すと単にコンテキスト消費が多くなるだけになってしまう
  - なので重要なのは検索から得られた情報を、うまく咀嚼して今の状況にあわせて解釈し、適切な形でメインエージェントへ返すこと

## 開発・インフラ関連データへのアクセス機能の提供

とにかくいろいろな権限を付けたりツールを用意してエージェントがアクセスできる状態を作る

- ソースコードリポジトリへの読み取りアクセス
  - アラート関連のエンドポイントやロジックの実装を直接確認
  - 入力検証、認証実装、使用ライブラリのバージョンなどを自動抽出
  - これについては単純にアクセスできれば良いというわけではなく、コードを追跡するようなエージェントとしての振る舞いが必要
    - これはAIコーディングエージェントの方が得意な領域
    - またコストも掛かるのでクリティカルそうなアラートだけに絞るみたいな工夫も必要そう
- IaC(Infrastructure as Code)および実際のインフラ情報の読み取り
  - 権限設定、ネットワーク構成、公開範囲などをTerraform/CloudFormationから読み取り
  - さらに実際のインフラにアクセスして情報を読み取る
    - 例えばCloud Asset Inventoryの情報をBQに外出しして検索みたいなのもできなくはないが、やはり生の情報が必要
- CI/CDパイプラインやデプロイ履歴へのアクセス
  - 最近のデプロイタイミングとアラート発生時刻を突き合わせ
  - デプロイ内容から新機能起因かどうかを判断
  - あとどのソースコードがどこにどういう形でデプロイされたかみたいなのを追跡できることも重要
    - 意外とソースコードのリポジトリと実稼働プロダクトが綺麗に繋がらない場合もある
    - これを人間がちまちま調べるのではなくエージェントにやらせたいよね
- 依存関係管理ツール(Dependabot、Renovateなど)との連携
  - 既知の脆弱性や未適用パッチの情報を取得
  - CVEやセキュリティアドバイザリとの関連を自動判定

## 関係者との対話の代行

関係者に「聞く・問い合わせる」ということ自体をエージェントに代行させる

- システムオーナーやSREへの自動問い合わせ
  - 不明な設定や意図が不明なアラートについてチャットシステム（Slack/Teams）で質問を代行させる
  - そこまで高度な会話をもとめないでも「Yes」「No」で答えられるようにして、ボタンで回答させるとかで良いはず
  - 人間の回答を待ってから深刻度判定を継続
  - あるいは他に聞いたらいい人を指名してもらうみたいなのもありかもしれない

## マルチエージェント化

- といくつか方法を挙げてきたが、これらのアプローチは1つ1つの処理がとても複雑
- そうするとコンテキスト限界だけでなく余計な処理によるコンテキスト汚染もかなり気にする必要がでてくる
- こういった側面を考えるとやはりマルチエージェント化が必要である
- マルチエージェントは専門性をエージェントごとに分離すると思われがちだが、個人的にそれはちょっと違くて、本質は「タスクの専門家」を作ることだと考えている
  - 例えばここまでの例で言うと「資料検索の専門家」「ポリシー解釈の専門家」「ソースコード分析の専門家」みたいな感じ
  - 人間の単位にみる専門性とは違う
  - ツール利用の最適化
    - 各エージェントが特化したツールセットを持つことで効率化
    - 例:コード分析エージェントはGitHub API、インフラエージェントはクラウドAPI
    - 利用できるツールが多すぎると混乱するというのもあるので、そこの防止策でもある
- マルチエージェントについては並列性も利点として挙げられるが、これも個人的にはあまり本質ではない
  - 直列でも正しく問題を解決できればものすごく価値がある
  - 依存関係を本当に正しく事前に計画できるのか疑義がある
  - 「早すぎる最適化は悪手」
- ということで現状世間で言われているマルチエージェントとは本質がややずれるものの、エージェントを分散させるのが、今後の発展の1つの鍵であると予想される
- またマルチエージェントでは主たるエージェントがサブエージェントを使いこなすものとイメージされがちだが、並列する2つのエージェントを用意して意見を戦わせるという手法も考えられる
  - 異なる前提や異なるモデル、プロンプトを与えることによって違う視点を持たせられる
  - 人間の役割分担と同じく、例えばセキュリティ担当としても深刻度と事業担当者としての深刻度というのは異なってくる
  - そのため異なる役割を与えた時の結論は違うはずで、それを綱引きさせるというのは重要な判断においてはありえると考えている
    - もちろんコストや時間はかかる
  - 3つのエージェントでそれを判断するような仕組みが作れると、某スーパーコンピューターみたいになりそう
    - 実際に複数エージェントを戦わせる手法（ensemble, debateなど）は研究は進められているがまだ実用段階ではないとのこと
    - 逆に精度が下がる可能性もあるらしい
    - とはいえ夢があるよね

# まとめ

